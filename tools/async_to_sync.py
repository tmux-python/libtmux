#!/usr/bin/env python
"""Convert async code in libtmux to sync code.

This tool is adapted from psycopg's async_to_sync.py to work with libtmux.
It transforms async-first implementation into sync versions.

Usage:
    python tools/async_to_sync.py                    # Convert all files
    python tools/async_to_sync.py --check            # Check for differences
    python tools/async_to_sync.py src/libtmux/server_async.py  # Convert specific file
"""

from __future__ import annotations

import os
import sys
import logging
import subprocess as sp
from copy import deepcopy
from typing import Any
from pathlib import Path
from argparse import ArgumentParser, Namespace, RawDescriptionHelpFormatter
from concurrent.futures import ProcessPoolExecutor

import ast_comments as ast  # type: ignore

# The version of Python officially used for the conversion.
PYVER = "3.11"

ALL_INPUTS = """
    src/libtmux/common_async.py
    src/libtmux/server_async.py
    src/libtmux/session_async.py
    src/libtmux/window_async.py
    src/libtmux/pane_async.py
""".split()

PROJECT_DIR = Path(__file__).parent.parent
SCRIPT_NAME = os.path.basename(sys.argv[0])

logger = logging.getLogger()


def main() -> int:
    logging.basicConfig(level=logging.INFO, format="%(levelname)s %(message)s")

    opt = parse_cmdline()

    if not opt.all:
        inputs, outputs = [], []
        for fpin in opt.inputs:
            fpout = fpin.parent / fpin.name.replace("_async", "")
            if fpout.exists() and fpout.stat().st_mtime >= fpin.stat().st_mtime:
                logger.debug("not converting %s as %s is up to date", fpin, fpout)
                continue
            inputs.append(fpin)
            outputs.append(fpout)
        if not outputs:
            logger.info("all output files are up to date, nothing to do")
            return 0

    else:
        inputs = opt.inputs
        outputs = [fpin.parent / fpin.name.replace("_async", "") for fpin in inputs]

    if opt.jobs == 1:
        logger.debug("multi-processing disabled")
        for fpin, fpout in zip(inputs, outputs):
            convert(fpin, fpout)
    else:
        with ProcessPoolExecutor(max_workers=opt.jobs) as executor:
            executor.map(convert, inputs, outputs)

    if opt.check:
        return check([str(o) for o in outputs])

    return 0


def convert(fpin: Path, fpout: Path) -> None:
    logger.info("converting %s", fpin)
    with fpin.open() as f:
        source = f.read()

    tree = ast.parse(source, filename=str(fpin))
    tree = async_to_sync(tree, filepath=fpin)
    output = tree_to_str(tree, fpin)

    with fpout.open("w") as f:
        print(output, file=f)

    sp.check_call(["ruff", "format", str(fpout)])
    sp.check_call(["ruff", "check", "--fix", str(fpout)])


def check(outputs: list[str]) -> int:
    try:
        sp.check_call(["git", "diff", "--exit-code"] + outputs)
    except sp.CalledProcessError:
        logger.error("sync and async files... out of sync!")
        return 1

    # Check that all the files to convert are included in the ALL_INPUTS files list
    cmdline = ["git", "grep", "-l", f"auto-generated by '{SCRIPT_NAME}'", "**.py"]
    try:
        maybe_conv = sp.check_output(cmdline, cwd=str(PROJECT_DIR), text=True).split()
    except sp.CalledProcessError:
        # No files yet, that's okay during initial setup
        return 0

    if not maybe_conv:
        logger.warning("no generated files found yet")
        return 0

    unk_conv = sorted(set(maybe_conv) - {fn.replace("_async", "") for fn in ALL_INPUTS})
    if unk_conv:
        logger.error(
            "files converted by %s but not included in ALL_INPUTS: %s",
            SCRIPT_NAME,
            ", ".join(unk_conv),
        )
        return 1

    return 0


def async_to_sync(tree: ast.AST, filepath: Path | None = None) -> ast.AST:
    tree = BlanksInserter().visit(tree)
    tree = RenameAsyncToSync().visit(tree)
    tree = AsyncToSync().visit(tree)
    return tree


def tree_to_str(tree: ast.AST, filepath: Path) -> str:
    rv = f"""\
# WARNING: this file is auto-generated by '{SCRIPT_NAME}'
# from the original file '{filepath.name}'
# DO NOT CHANGE! Change the original file instead.
"""
    rv += unparse(tree)
    return rv


class AsyncToSync(ast.NodeTransformer):  # type: ignore
    """Transform async constructs to sync equivalents."""

    def visit_AsyncFunctionDef(self, node: ast.AsyncFunctionDef) -> ast.AST:
        new_node = ast.FunctionDef(**node.__dict__)
        ast.copy_location(new_node, node)
        self.visit(new_node)
        return new_node

    def visit_AsyncFor(self, node: ast.AsyncFor) -> ast.AST:
        new_node = ast.For(**node.__dict__)
        ast.copy_location(new_node, node)
        self.visit(new_node)
        return new_node

    def visit_AsyncWith(self, node: ast.AsyncWith) -> ast.AST:
        new_node = ast.With(**node.__dict__)
        ast.copy_location(new_node, node)
        self.visit(new_node)
        return new_node

    def visit_Await(self, node: ast.Await) -> ast.AST:
        new_node = node.value
        self.visit(new_node)
        return new_node

    def visit_GeneratorExp(self, node: ast.GeneratorExp) -> ast.AST:
        if isinstance(node.elt, ast.Await):
            node.elt = node.elt.value

        for gen in node.generators:
            if gen.is_async:
                gen.is_async = 0

        return node


class RenameAsyncToSync(ast.NodeTransformer):  # type: ignore
    """Rename async-specific names to sync equivalents."""

    names_map = {
        # Class names
        "AsyncServer": "Server",
        "AsyncSession": "Session",
        "AsyncWindow": "Window",
        "AsyncPane": "Pane",
        "AsyncTmuxObj": "TmuxObj",
        "AsyncEnvironmentMixin": "EnvironmentMixin",
        "tmux_cmd_async": "tmux_cmd",
        # Method names
        "__aenter__": "__enter__",
        "__aexit__": "__exit__",
        "__aiter__": "__iter__",
        "__anext__": "__next__",
        # Function names and attributes
        "acreate": "create",
        "afetch": "fetch",
        "acmd": "cmd",
        # Module names
        "common_async": "common",
        "server_async": "server",
        "session_async": "session",
        "window_async": "window",
        "pane_async": "pane",
        # Utilities
        "asynccontextmanager": "contextmanager",
    }

    def visit_Module(self, node: ast.Module) -> ast.AST:
        self._fix_docstring(node.body)
        self.generic_visit(node)
        return node

    def visit_AsyncFunctionDef(self, node: ast.AsyncFunctionDef) -> ast.AST:
        self._fix_docstring(node.body)
        node.name = self.names_map.get(node.name, node.name)
        for arg in node.args.args:
            arg.arg = self.names_map.get(arg.arg, arg.arg)
        self.generic_visit(node)
        return node

    def visit_FunctionDef(self, node: ast.FunctionDef) -> ast.AST:
        self._fix_docstring(node.body)
        node.name = self.names_map.get(node.name, node.name)
        self.generic_visit(node)
        return node

    def _fix_docstring(self, body: list[ast.AST]) -> None:
        doc: str
        match body and body[0]:
            case ast.Expr(value=ast.Constant(value=str(doc))):
                doc = doc.replace("Async", "")
                doc = doc.replace("async ", "")
                body[0].value.value = doc

    def visit_ClassDef(self, node: ast.ClassDef) -> ast.AST:
        self._fix_docstring(node.body)
        node.name = self.names_map.get(node.name, node.name)
        self.generic_visit(node)
        return node

    def visit_ImportFrom(self, node: ast.ImportFrom) -> ast.AST | None:
        if node.module:
            node.module = self.names_map.get(node.module, node.module)
        for n in node.names:
            n.name = self.names_map.get(n.name, n.name)
        return node

    def visit_Name(self, node: ast.Name) -> ast.AST:
        if node.id in self.names_map:
            node.id = self.names_map[node.id]
        return node

    def visit_Attribute(self, node: ast.Attribute) -> ast.AST:
        if node.attr in self.names_map:
            node.attr = self.names_map[node.attr]
        self.generic_visit(node)
        return node


class BlanksInserter(ast.NodeTransformer):  # type: ignore
    """Restore missing spaces in the source."""

    def generic_visit(self, node: ast.AST) -> ast.AST:
        if isinstance(getattr(node, "body", None), list):
            node.body = self._inject_blanks(node.body)
        super().generic_visit(node)
        return node

    def _inject_blanks(self, body: list[ast.Node]) -> list[ast.AST]:
        if not body:
            return body

        new_body = []
        before = body[0]
        new_body.append(before)
        for i in range(1, len(body)):
            after = body[i]
            if after.lineno - before.end_lineno - 1 > 0:
                # Inserting one blank is enough.
                blank = ast.Comment(
                    value="",
                    inline=False,
                    lineno=before.end_lineno + 1,
                    end_lineno=before.end_lineno + 1,
                    col_offset=0,
                    end_col_offset=0,
                )
                new_body.append(blank)
            new_body.append(after)
            before = after

        return new_body


def unparse(tree: ast.AST) -> str:
    return Unparser().visit(tree)


class Unparser(ast._Unparser):  # type: ignore
    """Try to emit long strings as multiline."""

    def _write_constant(self, value: Any) -> None:
        if isinstance(value, str) and len(value) > 50:
            self._write_str_avoiding_backslashes(value)
        else:
            super()._write_constant(value)


def parse_cmdline() -> Namespace:
    parser = ArgumentParser(
        description=__doc__, formatter_class=RawDescriptionHelpFormatter
    )

    parser.add_argument(
        "--check", action="store_true", help="return with error in case of differences"
    )
    parser.add_argument(
        "-B",
        "--all",
        action="store_true",
        help="process specified files without checking last modification times",
    )
    parser.add_argument(
        "-j",
        "--jobs",
        type=int,
        metavar="N",
        help=(
            "process files concurrently using at most N workers; "
            "if unspecified, the number of processors on the machine will be used"
        ),
    )
    parser.add_argument(
        "inputs",
        metavar="FILE",
        nargs="*",
        type=Path,
        help="the files to process (process all files if not specified)",
    )

    if not (opt := parser.parse_args()).inputs:
        opt.inputs = [PROJECT_DIR / Path(fn) for fn in ALL_INPUTS]

    fp: Path
    for fp in opt.inputs:
        if not fp.is_file():
            parser.error("not a file: %s" % fp)
        if "_async" not in fp.name:
            parser.error("file should have '_async' in the name: %s" % fp)

    return opt


if __name__ == "__main__":
    sys.exit(main())
